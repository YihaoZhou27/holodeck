{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import holodeck as holo\n",
    "from holodeck import single_sources, utils, plot, detstats, anisotropy\n",
    "from holodeck.constants import YR\n",
    "\n",
    "import numpy as np\n",
    "import healpy as hp\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import h5py\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set Up\n",
    "\n",
    "## Read in library\n",
    "\n",
    "ss16 has 10 loudest, definitely will replace this with a better library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sspath = '/Users/emigardiner/GWs/holodeck/brc_output/ss51-2023-05-22_uniform_07a_n1000_r100_f40_l2000'\n",
    "\n",
    "# hdfname = sspath+'/sam_lib.hdf5'\n",
    "# ssfile = h5py.File(hdfname, 'r')\n",
    "# print(list(ssfile.keys()))\n",
    "# hc_ss = ssfile['hc_ss'][...]\n",
    "# hc_bg = ssfile['hc_bg'][...]\n",
    "# fobs = ssfile['fobs'][:]\n",
    "# dfobs = ssfile['dfobs'][:]\n",
    "# ssfile.close()\n",
    "\n",
    "# shape = hc_ss.shape\n",
    "# nsamps, nfreqs, nreals, nloudest = shape[0], shape[1], shape[2], shape[3]\n",
    "# print('N,F,R,L =', nsamps, nfreqs, nreals, nloudest)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find Best Samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hc_ref15_10yr = 11.2*10**-15 \n",
    "# nsort, fidx, hc_tt, hc_ref15 = detstats.rank_samples(hc_ss, hc_bg, fobs, hc_ref=hc_ref15_10yr, ret_all=True)\n",
    "# nbest = 100\n",
    "# print(hc_ref15)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load/Calculate pixel strains and harmonic coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# npix = anisotropy.NPIX\n",
    "# lmax = anisotropy.LMAX\n",
    "\n",
    "# Cl_best = np.zeros((nbest, nfreqs, nreals, lmax+1 ))\n",
    "# moll_hc_best = np.zeros((nbest, nfreqs, nreals, npix))\n",
    "# for nn in range(nbest):\n",
    "#     print('on nn=%d out of nbest=%d' % (nn,nbest))\n",
    "#     moll_hc_best[nn,...], Cl_best[nn,...] = anisotropy.sph_harm_from_hc(hc_ss[nsort[nn]], \n",
    "#                                             hc_bg[nsort[nn]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.savez(sspath+'sph_harmonics.npz', nsort=nsort, fidx=fidx, hc_tt=hc_tt, hc_ref15=hc_ref15, ss_shape=shape,\n",
    "#          moll_hc_best=moll_hc_best, Cl_best=Cl_best, nside=nside, lmax=lmax, fobs=fobs)\n",
    "\n",
    "sph_harm_file = np.load('/Users/emigardiner/GWs/holodeck/brc_output/ss51-2023-05-22_uniform_07a_n1000_r100_f40_l2000/anisotropy/sph_harm_lmax6_nside32_nbest100.npz')\n",
    "\n",
    "# load ss info\n",
    "shape = sph_harm_file['ss_shape']\n",
    "nsamps, nfreqs, nreals, nloudest = shape[0], shape[1], shape[2], shape[3]\n",
    "fobs = sph_harm_file['fobs']\n",
    "\n",
    "# load ranking info\n",
    "nsort = sph_harm_file['nsort']\n",
    "fidx = sph_harm_file['fidx']\n",
    "hc_tt = sph_harm_file['hc_tt']\n",
    "hc_ref15 = sph_harm_file['hc_ref15']\n",
    "\n",
    "# load harmonics info\n",
    "nside = sph_harm_file['nside']\n",
    "lmax  = sph_harm_file['lmax']\n",
    "moll_hc_best = sph_harm_file['moll_hc_best']\n",
    "Cl_best = sph_harm_file['Cl_best']\n",
    "nbest = len(moll_hc_best)\n",
    "\n",
    "sph_harm_file.close()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lvals = np.arange(lmax+1)\n",
    "fobs_nHz = fobs*10**9\n",
    "fobs_yrs = fobs*YR\n",
    "ff_labels = (0,9,19,29,39)\n",
    "nshow = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_ClC0_medians(xx, Cl_best, lmax, nshow):\n",
    "    fig, ax = plot.figax(figsize=(8,5), xlabel=plot.LABEL_GW_FREQUENCY_YR, ylabel='$C_{\\ell>0}/C_0$')\n",
    "\n",
    "    yy = Cl_best[:,:,:,1:]/Cl_best[:,:,:,0,np.newaxis] # (B,F,R,l)\n",
    "    yy = np.median(yy, axis=-1) # (B,F,l) median over realizations\n",
    "\n",
    "    colors = ['k', 'b', 'r', 'g', 'c', 'm']\n",
    "    for ll in range(lmax):\n",
    "        ax.plot(xx, np.median(yy[:,:,ll], axis=0), color=colors[ll], label='median of samples, $l=%d$' % ll)\n",
    "        for pp in [50, 98]:\n",
    "            percs = pp/2\n",
    "            percs = [50-percs, 50+percs]\n",
    "            ax.fill_between(xx, *np.percentile(yy[:,:,ll], percs, axis=0), alpha=0.1, color=colors[ll])\n",
    "        \n",
    "        for bb in range(0,nshow):\n",
    "            if ll==0 and bb==0:\n",
    "                label = \"individual best samples, median of realizations\"\n",
    "            else: label=None\n",
    "            ax.plot(xx, yy[bb,:,ll], color=colors[ll], linestyle=':', alpha=0.1,\n",
    "                                 linewidth=1, label=label)\n",
    "        ax.legend()\n",
    "        plot._twin_hz(ax, nano=False)\n",
    "    \n",
    "    # ax.set_title('50%% and 98%% confidence intervals of the %d best samples \\nusing realizations medians, lmax=%d'\n",
    "    #             % (nbest, lmax))\n",
    "    return fig\n",
    "fig = plot_ClC0_medians(fobs_yrs, Cl_best, lmax, nshow=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def plot_Clg0_llp1_medians(xx, Cl_best, lmax, nshow):\n",
    "#     fig, ax = plot.figax(figsize=(8,5), xlabel=plot.LABEL_GW_FREQUENCY_YR, ylabel='$C_{\\ell>0}/C_0$')\n",
    "\n",
    "#     yy = np.sum(Cl_best[:,:,:,1:], axis=-1)/Cl_best[:,:,:,0,] # (B,F,R)\n",
    "#     yy = np.median(yy, axis=-1) # (B,F) median over realizations\n",
    "\n",
    "#     ax.plot(xx, np.median(yy, axis=0), color='k', label='median of samples, $l_\\mathrm{max}=%d$' % lmax)\n",
    "#     for pp in [50, 98]:\n",
    "#         percs = pp/2\n",
    "#         percs = [50-percs, 50+percs]\n",
    "#         ax.fill_between(xx, *np.percentile(yy, percs, axis=0), alpha=0.1, color='k')\n",
    "\n",
    "#     colors = cm.rainbow(np.linspace(1, 0, nshow))\n",
    "#     bb=0\n",
    "#     ax.plot(xx, yy[bb,:], color=colors[bb], linestyle=':', alpha=0.4,\n",
    "#                 linewidth=1, label=\"individual best samples, median of realizations\")\n",
    "#     for bb in range(1,nshow):\n",
    "#         ax.plot(xx, yy[bb,:], color=colors[bb], linestyle=':', alpha=0.4,\n",
    "#                 linewidth=1)\n",
    "#     ax.legend()\n",
    "#     plot._twin_hz(ax, nano=False)\n",
    "    \n",
    "#     # ax.set_title('50%% and 98%% confidence intervals of the %d best samples \\nusing realizations medians, lmax=%d'\n",
    "#     #             % (nbest, lmax))\n",
    "#     return fig\n",
    "# fig = plot_Clg0_llp1_medians(fobs_yrs, Cl_best, lmax, nshow=50)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add Nihan's Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# decision threshold from the frequentist analysis for l = 0 through l = 6\n",
    "freq_dthresh = np.array([1.        , 0.39622564, 0.32362566, 0.20984702, 0.11960839,\n",
    "       0.07806638, 0.04426357])\n",
    "\n",
    "# This is for the all-band Bayesian analysis from l = 1 to l = 6:\n",
    "bayes_Cl = np.array([0.24187743, 0.17480158, 0.10009671, 0.08109598, 0.05493891,\n",
    "       0.0317599 ])\n",
    "\n",
    "# And these are the per-frequency Bayesian upper limits, \n",
    "# where each row represents the frequency bin from low to high (0 to 4) \n",
    "# and then each column is the spherical harmonic multipole from l = 1 to l = 6:\n",
    "# (F, l)\n",
    "Cl_nihan = np.array([\n",
    "    [0.20216773, 0.14690035, 0.09676646, 0.07453352, 0.05500382, 0.03177427],\n",
    "    [0.21201336, 0.14884939, 0.10545698, 0.07734305, 0.05257189, 0.03090662],\n",
    "    [0.20840993, 0.14836757, 0.09854803, 0.07205384, 0.05409881, 0.03305785],\n",
    "    [0.19788951, 0.15765126, 0.09615489, 0.07475364, 0.0527356 , 0.03113331],\n",
    "    [0.20182648, 0.14745265, 0.09681202, 0.0746824 , 0.05503161, 0.0317012 ]])\n",
    "print(Cl_nihan.shape)\n",
    "\n",
    "freq_bins_Hz = np.array([2.0, 4.0, 5.9, 7.9, 9.9]) *10**-9 # Hz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_ClC0_medians(xx, Cl_best, lmax, nshow, xx_Nihan, Cl_nihan):\n",
    "    fig, ax = plot.figax(figsize=(8,5), xlabel=plot.LABEL_GW_FREQUENCY_YR, ylabel='$C_{\\ell}/C_0$')\n",
    "\n",
    "    yy = Cl_best[:,:,:,1:]/Cl_best[:,:,:,0,np.newaxis] # (B,F,R,l)\n",
    "    yy = np.median(yy, axis=-1) # (B,F,l) median over realizations\n",
    "\n",
    "    colors = ['k', 'b', 'r', 'g', 'c', 'm']\n",
    "    for ll in range(lmax):\n",
    "        ax.plot(xx, np.median(yy[:,:,ll], axis=0), color=colors[ll]) #, label='median of samples, $l=%d$' % ll)\n",
    "        for pp in [50, 98]:\n",
    "            percs = pp/2\n",
    "            percs = [50-percs, 50+percs]\n",
    "            ax.fill_between(xx, *np.percentile(yy[:,:,ll], percs, axis=0), alpha=0.1, color=colors[ll])\n",
    "        \n",
    "        for bb in range(0,nshow):\n",
    "            # if ll==0 and bb==0:\n",
    "            #     label = \"individual best samples, median of realizations\"\n",
    "            # else: \n",
    "            label=None\n",
    "            ax.plot(xx, yy[bb,:,ll], color=colors[ll], linestyle=':', alpha=0.1,\n",
    "                                 linewidth=1, label=label)\n",
    "            \n",
    "        # Add Nihan's data\n",
    "        ax.plot(xx_Nihan, Cl_nihan[:,ll]/Cl_nihan[:,0], \n",
    "                label = '$l=%d$' % (ll+1), \n",
    "            color=colors[ll], marker='o', ms=8)\n",
    "        \n",
    "        plot._twin_hz(ax, nano=False)\n",
    "    \n",
    "    # ax.set_title('50%% and 98%% confidence intervals of the %d best samples \\nusing realizations medians, lmax=%d'\n",
    "    #             % (nbest, lmax))\n",
    "    return fig\n",
    "# fig1 = plot_ClC0_medians(fobs_yrs, Cl_best, lmax, nshow=10, xx_Nihan=freq_bins_Hz * YR, Cl_nihan=Cl_nihan)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig1 = plot_ClC0_medians(fobs_yrs, Cl_best, lmax, nshow=10, xx_Nihan=freq_bins_Hz * YR, Cl_nihan=Cl_nihan)\n",
    "ax = fig1.axes[0]\n",
    "\n",
    "# Sato-Polito & Kamionkowski\n",
    "spk_xx = np.array([3.5*10**-9, 1.25*10**-8, 1*10**-7])\n",
    "spk_yy = np.array([1*10**-5, 1*10**-3, 1*10**-1])\n",
    "\n",
    "ax.plot(spk_xx * YR, spk_yy, label='SP & K', color='tab:orange')\n",
    "ax.set_xlim(fobs[0]*YR-.005, 1)\n",
    "\n",
    "# fig1.legend(bbox_to_anchor=(0,0), loc='upper left', bbox_transform=ax.transAxes)\n",
    "ax.legend(loc='lower right', ncols=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig = plot_ClC0_medians(fobs_yrs, Cl_best, lmax, nshow=100)\n",
    "# ax = fig.axes[0]\n",
    "\n",
    "# xx = freq_bins_Hz * YR \n",
    "# for ll in range(len(Cl_nihan[0])):\n",
    "    \n",
    "\n",
    "# ax.set_xlim(0.18*10**-8*YR, 1.2*10**-8*YR)\n",
    "# # ax.set_xscale('linear')\n",
    "# fig.legend(loc='lower right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig = plot_Clg0_llp1_medians(fobs_yrs, Cl_best, lmax, nshow=50)\n",
    "# ax = fig.axes[0]\n",
    "\n",
    "# xx = freq_bins_Hz * YR \n",
    "# ax.plot(xx, Clg0_nihan, label = 'per-frequency Bayesian upper limits', color='tab:blue', marker='o', ms=8)\n",
    "\n",
    "# # ax.set_xlim(0.18*10**-8*YR, 1.2*10**-8*YR)\n",
    "# ax.legend(loc='lower right')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add Sato-Polito & Kamionkowski"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plot_Clg0_llp1_medians(fobs_yrs, Cl_best, lmax, nshow=50)\n",
    "ax = fig.axes[0]\n",
    "\n",
    "xx = freq_bins_Hz * YR \n",
    "ax.plot(xx, Clg0_nihan, label = 'per-frequency Bayesian upper limits', color='tab:blue', marker='o', ms=8)\n",
    "\n",
    "# Sato-Polito & Kamionkowski\n",
    "spk_xx = np.array([3.5*10**-9, 1.25*10**-8, 1*10**-7])\n",
    "spk_yy = np.array([1*10**-5, 1*10**-3, 1*10**-1])\n",
    "\n",
    "ax.plot(spk_xx * YR, spk_yy, label='SP & K Rough Estimate', color='tab:orange')\n",
    "ax.set_xlim(0, np.max(fobs_yrs))\n",
    "ax.legend()\n",
    "fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(nsort)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sspath = '/Users/emigardiner/GWs/holodeck/brc_output/ss51-2023-05-22_uniform_07a_n1000_r100_f40_l2000'\n",
    "\n",
    "hdfname = sspath+'/sam_lib.hdf5'\n",
    "ssfile = h5py.File(hdfname, 'r')\n",
    "print(list(ssfile.keys()))\n",
    "print('Best sample:', nsort[0])\n",
    "hc_ss = ssfile['hc_ss'][nsort[0],...]\n",
    "hc_bg = ssfile['hc_bg'][nsort[0],...]\n",
    "fobs = ssfile['fobs'][:]\n",
    "ssfile.close()\n",
    "\n",
    "shape = hc_ss.shape\n",
    "nfreqs, nreals, nloudest = shape[0], shape[1], shape[2]\n",
    "print('F,R,L =', nfreqs, nreals, nloudest)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "holo310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
